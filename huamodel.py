from keras.utils import plot_model


import os
import keras.layers as KL
import keras.models as KM
import keras.optimizers as KO
import tensorflow as tf
from keras.callbacks import CSVLogger, ModelCheckpoint
from keras import callbacks as K
import os
import datetime
import numpy as np
from lib import losses as ls


class RPN:

    def __init__(self, config, mode='train'):
        assert mode in ['train', 'inference']
        self.config = config

        # Build the model
        self.model = self.build_entire_model(mode)
        print(self.model.summary())
        plot_model(self.model, to_file='model2.png')

    @staticmethod
    def build_backbone(input_tensor, architecture, stage5=False, train_bn=None):
 

        def identity_block(tensor, kernel_size, filters, stage, block, use_bias=True):
 
            nb_filter1, nb_filter2, nb_filter3 = filters
            conv_name_base = 'res' + str(stage) + block + '_branch'
            bn_name_base = 'bn' + str(stage) + block + '_branch'

            y = KL.Conv2D(nb_filter1, (1, 1), name=conv_name_base + '2a', use_bias=use_bias)(tensor)
            y = KL.BatchNormalization(name=bn_name_base + '2a')(y, training=train_bn)

            y = KL.Activation('relu', name='res' + str(stage) + block + '_out')(y)
            return y

        def conv_block(tensor, kernel_size, filters, stage, block, strides=(2, 2), use_bias=True):


            nb_filter1, nb_filter2, nb_filter3 = filters
            conv_name_base = 'res' + str(stage) + block + '_branch'
            bn_name_base = 'bn' + str(stage) + block + '_branch'

            y = KL.Conv2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', use_bias=use_bias)(
                tensor)
            y = KL.BatchNormalization(name=bn_name_base + '2a')(y, training=train_bn)

            y = KL.Activation('relu', name='res' + str(stage) + block + '_out')(y)
            return y

        assert architecture in ["resnet50", "resnet101"]

  
        # Stage 2
        
        C2 =C3=C4=C5= input_tensor

        return [ C2, C3, C4, C5]

    def build_feature_maps(self, input_tensor):



        # Don't create the head (stage 5), so we pick the 4th item in the list.
        C2, C3, C4, C5 = self.build_backbone(input_tensor, self.config.BACKBONE, stage5=True,
                                                train_bn=self.config.TRAIN_BN)

        # Top-down Layers
        #P5 = KL.Conv2D(self.config.TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c5p5')(C5)


        # Attach 3x3 conv to all P layers to get the final feature maps.

        P5 =P2=P3=P4= P6=KL.Conv2D(self.config.TOP_DOWN_PYRAMID_SIZE, (3, 3), padding="SAME", activation='relu', name="fpn_p5")(C5)

        # P6 is used for the 5th anchor scale in RPN. Generated by sub-sampling from P5 with stride of 2.
        #P6 = KL.MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)

        # Note that P6 is used in RPN, but not in the classifier heads.
        return [P2, P3, P4, P5, P6]

    @staticmethod
    def build_rpn_model(anchor_stride, anchors_per_location, depth):


        input_feature_map = KL.Input(shape=[None, None, depth], name="input_rpn_feature_map")

        # Shared convolutional base of the RPN
        shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride,
                           name='rpn_conv_shared')(input_feature_map)

        # Anchor Score. [batch, height, width, anchors per location * 2].
        x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid', activation='linear',
                      name='rpn_class_raw')(shared)

        # Reshape to [batch, anchors, 2]
        rpn_class_logits = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x)

        # Softmax on last dimension of BG/FG.
        rpn_probs = KL.Activation("softmax", name="rpn_class_xxx")(rpn_class_logits)

        # Bounding box refinement. [batch, H, W, anchors per location * depth]
        # where depth is [x, y, log(w), log(h)]
        x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding="valid", activation='linear', name='rpn_bbox_pred')(
            shared)

        # Reshape to [batch, anchors, 4]
        rpn_bbox = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x)

        outputs = [rpn_class_logits, rpn_probs, rpn_bbox]
        return KM.Model([input_feature_map], outputs, name="rpn_model")

    def build_entire_model(self, mode='train'):

        assert mode in ['train', 'inference']

        # Input image
        input_tensor = KL.Input(shape=[self.config.IMAGE_SHAPE[0], self.config.IMAGE_SHAPE[1],
                                       self.config.NUM_CHANNELS], name="input_image")

        # RPN feature maps
        rpn_feature_maps = self.build_feature_maps(input_tensor)

        # RPN Network
        rpn = self.build_rpn_model(self.config.ANCHOR_STRIDE, len(self.config.ANCHOR_RATIOS),
                                   self.config.TOP_DOWN_PYRAMID_SIZE)

        # Restructures [[a1, b1, c1], [a2, b2, c2]] -> [[a1, a2], [b1, b2], [c1, c2]]
        layer_outputs = []
        for layer in rpn_feature_maps:
            layer_outputs.append(rpn([layer]))
        output_names = ["rpn_class_logits", "rpn_class", "rpn_bbox"]
        rpn_outputs = list(zip(*layer_outputs))
        rpn_outputs = [KL.Concatenate(axis=1, name=n)(list(o)) for o, n in zip(rpn_outputs, output_names)]

        # Outputs of RPN
        rpn_class_logits, rpn_class, rpn_bbox = rpn_outputs

        # Loss functions
        # GT inputs to RPN
        input_rpn_match = KL.Input(shape=[None, 1], name="input_rpn_match", dtype=tf.int32)
        input_rpn_bbox = KL.Input(shape=[None, 4], name="input_rpn_bbox", dtype=tf.float32)
        rpn_class_loss = KL.Lambda(lambda x: ls.rpn_match_loss(*x), name="rpn_class_loss")(
                                   [input_rpn_match, rpn_class_logits])
        rpn_bbox_loss = KL.Lambda(lambda x: ls.rpn_bbox_loss(self.config, *x), name="rpn_bbox_loss")(
                                  [input_rpn_match, input_rpn_bbox, rpn_bbox])

        # Inputs and outputs of the model
        if mode == 'train':
            inputs = [input_tensor, input_rpn_match, input_rpn_bbox]
            outputs = [rpn_class_logits, rpn_class, rpn_bbox, rpn_class_loss, rpn_bbox_loss]
        elif mode == 'inference':
            inputs = [input_tensor]
            outputs = [rpn_class, rpn_bbox]

        # Set the model attribute
        return KM.Model(inputs, outputs, name='rpn')




class Config(object):

    # Name of the experiment
    NAME = 'pancreatitis'

    # Default logs directory to save weights of experiments
    LOGS = '/data/ydeng1/pancreatitis/fcn_3Dunet/fcn-rpn/keras-rpn-master/keras-rpn-master/logs/'

    # Time stamp of the experiment - generated automatically
    TIME_STAMP = None

    # Path to save trained weights in - generated automatically
    CNN_WEIGHTS_PATH = None

    # Batch size
    BATCH_SIZE = 32

    # Backbone
    BACKBONE = "resnet50"

    # Backbone strides to make feature map shapes
    BACKBONE_STRIDES = [4, 8, 16, 32, 64]

    # Size of the top-down layers used to build the feature pyramid
    TOP_DOWN_PYRAMID_SIZE = 128

    # Length of square anchor side in pixels
    ANCHOR_SCALES = (16, 32, 64, 128,256)

    # Ratios of anchors at each cell (width/height)
    ANCHOR_RATIOS = [0.5, 1, 2]

    # Anchor stride
    ANCHOR_STRIDE = 1

    # How many anchors per image to use for RPN training
    TRAIN_ANCHORS_PER_IMAGE =256

    # Max ground truth bounding boxes
    MAX_GT_INSTANCES = 2

    # Input image resizing
    IMAGE_SHAPE = (512, 512)

    # Number of channels
    NUM_CHANNELS = 3

    # Image mean (RGB)
    MEAN_PIXEL = np.array([15.53, 14.56, 13.22])

    # Bounding box refinement standard deviation for RPN and final detections.
    RPN_BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])
    BBOX_STD_DEV = np.array([0.1, 0.1, 0.2, 0.2])

    # Learning rate and momentum
    LEARNING_RATE = 0.001
    LEARNING_MOMENTUM = 0.9

    # Weight decay regularization
    WEIGHT_DECAY = 0.0001

    # Loss weights for more precise optimization.
    LOSS_WEIGHTS = {"rpn_class_loss": 0.2, "rpn_bbox_loss": 1}
    
    #LOSS_WEIGHTS = {"rpn_class_loss": 1., "rpn_bbox_loss": 1.}
    
    # Train or freeze batch normalization layers
    #     None: Train BN layers. This is the normal mode
    #     False: Freeze BN layers. Good when using a small batch size
    #     True: (don't use). Set layer in training mode even when predicting
    TRAIN_BN = False  # Defaulting to False since batch size is often small

    # Gradient norm clipping
    GRADIENT_CLIP_NORM = 5.0

    def __init__(self):
        assert os.path.exists(self.LOGS)

    def create_training_directory(self):

        self.TIME_STAMP = datetime.datetime.strftime(datetime.datetime.now(), "%m-%d-%y_%H.%M.%S")

        try:
            os.mkdir(os.path.join(self.LOGS, self.NAME))
        except FileExistsError:
            pass

        try:
            os.mkdir(os.path.join(self.LOGS, self.NAME, self.TIME_STAMP))
        except FileExistsError:
            pass

        self.CNN_WEIGHTS_PATH = os.path.join(self.LOGS, self.NAME, self.TIME_STAMP, "cnn_weights")
        try:
            os.mkdir(self.CNN_WEIGHTS_PATH)
        except FileExistsError:
            pass
        
class NucleiConfig(Config):

    NAME = 'pancreatitis'

    # Data parameters
    IMAGE_SHAPE = (512, 512)
    ANCHOR_SCALES = (16, 32, 64, 128,256)
    TRAIN_ANCHORS_PER_IMAGE = 256
    MEAN_PIXEL = np.array([15.53, 14.56, 13.22])

    # Learning parameters
    LEARNING_RATE = 0.001
    LEARNING_MOMENTUM = 0.9
    BATCH_SIZE = 1
    EPOCHS = 300        
        
        
class NucleiInferenceConfig(NucleiConfig):

    # Data parameters
    IMAGE_SHAPE = (512, 512)
    ANCHOR_SCALES = (16, 32, 64, 128, 256)
    TRAIN_ANCHORS_PER_IMAGE = 128
    MEAN_PIXEL = np.array([15.53, 14.56, 13.22])

    LOGS = '/data/ydeng1/pancreatitis/fcn_3Dunet/fcn-rpn/keras-rpn-master/keras-rpn-master/logs/pancreatitis/'

    # Path to the weights file
    WEIGHTS_FILE ="/data/ydeng1/pancreatitis/fcn_3Dunet/fcn-rpn/keras-rpn-master/keras-rpn-master/logs/pancreatitis/02-26-20_18.30.25/cnn_weights/rpn_weights.82.hdf5"
           

def main():

    # Configuration
    config = NucleiConfig()

    # Dataset
    #dataset = {"train": NucleiSequence(TRAIN_PATH, config), "validation": NucleiSequence(VALIDATION_PATH, config)}
    
    # Region proposal network
    rpn = RPN(config)
    #rpn.train(dataset)
    plot_model(rpn, to_file='model_original.png')
    
if __name__ == '__main__':
    main()    